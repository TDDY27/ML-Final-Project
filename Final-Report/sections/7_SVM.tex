\subsection*{SVM}

\subsubsection*{Choosing the best model in SVM}

\quad In this section, we implement SVM model to predict the MLB result. 
SVM a.k.a. support vector machine can select multiple parameters to decide the data transformation method 
and hyperplane to seperate the data. To choose the best model, we use grid search by following parameters
\begin{lstlisting}[language=Python]
    param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.1, 1],
    'kernel': ['rbf', 'linear', 'poly']
    }
\end{lstlisting}
\quad After the bruteforce searching, the result turns out that 
( kernel : linear, C=1.0, gamma : scale ) and ( kernel : rbf, C=1.0, gamma : scale ) have the best performance 
which results in training data accuracy around 0.58 and validation data accuracy about 0.56 with 5-folds validations.
After submit the test results to the kaggle in stage 1 and stage 2, 
the first parameters combination turns out to be in 
stage 1 : pulic 0.56584, private 0.57142, and in stage 2 : public 0.50830, private 0.50980, 
and the second combinations results in stage 1 : public 0.57101, private 0.57110, stage 2 : public 0.57558, private 0.54656.

\subsubsection*{Linear Kernel SVM}
\quad The performance of the linear kernel SVM is relatively stable when comparing public and private test results. 
However, when the trained model is applied to stage 2 data, the accuracy drops significantly from approximately 0.57 to around 0.51. 
This suggests that the validation method used for the linear kernel may need improvement to better handle stage 2 predictions. 
We propose that since the RBF kernel achieves a stable 0.57 accuracy in stage 2 and the linear kernel is inherently a simpler model, 
overfitting is unlikely to be the primary issue. 
Instead, the linear model may be too simplistic to accurately predict stage 2 data, 
which spans the entire year, particularly with an unsuitable validation approach. Despite the instability in performance, 
the linear kernel's training speed is highly efficient, especially when the regularization parameter 
C is set below 100.

\subsubsection*{RBF Kernel SVM}
\quad The RBF kernel SVM demonstrates strong and stable accuracy, 
with only a slight drop in private test results during stage 2. 
With proper regularization, it effectively models and separates the data while minimizing overfitting, 
making it a reliable choice for this task. However, compared to the linear kernel, 
the RBF kernel requires more training time and is more prone to overfitting in certain scenarios. 
Additionally, the RBF kernel projects the data into an infinite-dimensional space, 
which reduces the model's interpretability. As a result, while it often achieves excellent prediction performance, 
it provides limited insight into the underlying patterns learned during training.



\subsubsection*{SVM with bagging and blending}

\quad Since both parameters combinations have the similar prediction accuracy in stage 1 public tests, we come up with an idea to combine those parameters combinations by 
bagging and blending with SVM. When it comes to bagging, we use bootstrapping to generate different model  
with kernel=linear and kernel=rbf by selecting different values in the maximum number of features 
(abbreviated as max\_feature which can increase the diverity of models), the maximum number of samples (maximum\_number of train samples 
abbreviated as max\_samples) and the number of estimator (the number of different hypothesis generated from bagging).

This time we utilize optuna package to help us find the best parameters by following commands 
(Since optuna can tune the parameters in more precision ways, we also take C and gamma into considerations to expect better outcomes ).
\begin{lstlisting}[language=Python]
    C = trial.suggest_loguniform('C', 0.1, 100.0)
    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])
    n_estimators = trial.suggest_int('n_estimators', 10, 50)
    max_samples = trial.suggest_float('max_samples', 0.5, 1.0)
    max_features = trial.suggest_float('max_features', 0.3, 1.0)
\end{lstlisting}
\quad After optimization with Optuna, 
And the submission result on stage 1 and stage 2 is corresponding to and .

\subsubsection*{Package references}
\begin{lstlisting}[language=Python]
sklearn, optuna
\end{lstlisting}